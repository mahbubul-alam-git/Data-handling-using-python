{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into a DataFrame\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# --- Data Exploration ---\n",
    "# Display total number of rows and columns\n",
    "print('Total rows and columns:', df.shape)\n",
    "\n",
    "# Get a summary of the dataset (data types, non-null counts, etc.)\n",
    "print(df.info())\n",
    "\n",
    "# Generate descriptive statistics for numerical columns (mean, std, min, max)\n",
    "print(df.describe())\n",
    "\n",
    "# --- Data Selection & Slicing ---\n",
    "# Extract and display the list of column names\n",
    "columns_list = df.columns.tolist()\n",
    "print(\"Columns:\", columns_list)\n",
    "\n",
    "# Create a subset DataFrame with specific features\n",
    "new_df = df[['Name', 'Sex', 'Age']]\n",
    "print(new_df.head())\n",
    "\n",
    "# Concatenate the first 10 rows and the last 5 rows for a quick overview\n",
    "result = pd.concat([df.iloc[:10], df.iloc[-5:]])\n",
    "print(result)\n",
    "\n",
    "# --- Categorical Analysis ---\n",
    "# Count occurrences of unique values in 'Survived' and 'Sex' columns\n",
    "print(\"Survival Count:\\n\", df['Survived'].value_counts())\n",
    "print(\"Gender Distribution:\\n\", df['Sex'].value_counts())\n",
    "\n",
    "# --- Data Filtering ---\n",
    "# Filter data: Female passengers older than 30\n",
    "female_over_30 = df[(df['Sex'] == 'female') & (df['Age'] > 30)]\n",
    "print(\"Females over 30:\\n\", female_over_30)\n",
    "\n",
    "# Filter data: Passengers in 1st Class who did not survive\n",
    "first_class_non_survivors = df[(df['Pclass'] == 1) & (df['Survived'] == 0)]\n",
    "print(\"1st Class Non-Survivors:\\n\", first_class_non_survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# --- Data Cleaning ---\n",
    "# Check for missing values in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values in 'Age' by filling them with the median age\n",
    "median_age = df['Age'].median()\n",
    "df['Age'] = df['Age'].fillna(median_age)\n",
    "\n",
    "# Drop the 'Cabin' column as it has too many missing values to be useful\n",
    "df = df.drop(['Cabin'], axis=1)\n",
    "\n",
    "# Fill missing values in 'Embarked' with the most common port ('S' for Southampton)\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# (Optional) Save the cleaned dataset to a new CSV file\n",
    "# df.to_csv('Titanic-Dataset-Cleaned.csv', index=False)\n",
    "\n",
    "# --- Data Analysis & Aggregation ---\n",
    "# Assuming 'df_clean' is our processed data\n",
    "df_clean = df \n",
    "\n",
    "# Calculate the average age grouped by gender\n",
    "average_age = df_clean.groupby('Sex')['Age'].mean()\n",
    "print(\"Average Age by Sex:\\n\", average_age)\n",
    "\n",
    "# Calculate survival rate grouped by Passenger Class\n",
    "average_pclass = df_clean.groupby('Pclass')['Survived'].mean()\n",
    "print(\"Survival Rate by Class:\\n\", average_pclass)\n",
    "\n",
    "# Create a pivot table to see Survival rates across both Sex and Pclass\n",
    "pivot = df_clean.pivot_table(values='Survived', index='Sex', columns='Pclass')\n",
    "print(\"Survival Pivot Table:\\n\", pivot)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "# Extract 'Title' (Mr, Mrs, Miss, etc.) from the 'Name' column using Regex\n",
    "df_clean['Title'] = df_clean['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Mapping Categorical 'Sex' to Numerical values (Encoding)\n",
    "df_clean['Sex_Encoded'] = df_clean['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Create a new feature 'FamilySize' by combining Siblings/Spouses and Parents/Children\n",
    "# Adding 1 to include the passenger themselves\n",
    "df_clean['FamilySize'] = df_clean['SibSp'] + df_clean['Parch'] + 1\n",
    "\n",
    "# Display the relationship between family components and the new FamilySize feature\n",
    "print(df_clean[['SibSp', 'Parch', 'FamilySize']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset-Cleaned.csv')\n",
    "\n",
    "# --- Outlier Detection using Interquartile Range (IQR) ---\n",
    "\n",
    "# Calculate the 1st Quartile (25th percentile) and 3rd Quartile (75th percentile)\n",
    "q1 = df['Fare'].quantile(0.25)\n",
    "q3 = df['Fare'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR (The range where the middle 50% of the data lies)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Define the lower and upper boundaries for outliers\n",
    "# Standard practice is 1.5 times the IQR below Q1 and above Q3\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Display the statistical boundaries\n",
    "print(f\"IQR for Fare: {iqr:.2f}\")\n",
    "print(f\"Lower Boundary: {lower_bound:.2f}\")\n",
    "print(f\"Upper Boundary: {upper_bound:.2f}\")\n",
    "\n",
    "# --- Identifying Outliers ---\n",
    "\n",
    "# Filter the dataset for rows where 'Fare' is outside the calculated boundaries\n",
    "outliers = df[(df['Fare'] > upper_bound) | (df['Fare'] < lower_bound)]\n",
    "\n",
    "# Display the total count and a preview of the outlier data points\n",
    "print(f\"Total Outliers Detected: {len(outliers)}\")\n",
    "print(\"Preview of Outlier Records (Name and Fare):\")\n",
    "print(outliers[['Name', 'Fare']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Categorical Encoding ---\n",
    "# Perform One-Hot Encoding on 'Sex' and 'Embarked' columns\n",
    "# This converts categorical text into binary (0 or 1) columns for Machine Learning models\n",
    "df_encoded = pd.get_dummies(df, columns=['Sex', 'Embarked'], dtype=int)\n",
    "print(\"Encoded DataFrame Preview:\\n\", df_encoded.head())\n",
    "\n",
    "# --- Advanced Filtering ---\n",
    "# Identify \"Solo Travelers\" between the ages of 20 and 40\n",
    "# Criteria: Age [20-40], no siblings/spouses (SibSp=0), and no parents/children (Parch=0)\n",
    "total_solo_adults = df[(df['Age'] >= 20) & (df['Age'] <= 40) & (df['SibSp'] == 0) & (df['Parch'] == 0)]\n",
    "print(\"Solo Travelers (Age 20-40):\\n\", total_solo_adults)\n",
    "\n",
    "# --- Data Sorting & Grouping ---\n",
    "# Reload cleaned data for a fresh analysis\n",
    "df = pd.read_csv('Titanic-Dataset-Cleaned.csv')\n",
    "\n",
    "# Find the top 3 most expensive tickets (Fares) for each Passenger Class (Pclass)\n",
    "# We sort by Fare descending, then group by Pclass and take the top 3 results\n",
    "top_3_fares = df.sort_values('Fare', ascending=False).groupby('Pclass').head(3)\n",
    "print(\"Top 3 Highest Fares per Class:\\n\", top_3_fares[['Pclass', 'PassengerId', 'Name', 'Fare']])\n",
    "\n",
    "# --- Merging DataFrames ---\n",
    "# Creating two separate subsets to demonstrate a \"Join\" or \"Merge\" operation\n",
    "df1 = df[['PassengerId', 'Name']]\n",
    "df2 = df[['PassengerId', 'Ticket']]\n",
    "\n",
    "# Merge (Join) the two DataFrames on the common key 'PassengerId'\n",
    "# This is similar to a SQL INNER JOIN\n",
    "merged_df = pd.merge(df1, df2, on='PassengerId')\n",
    "print(\"Successfully Merged DataFrame:\\n\", merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
